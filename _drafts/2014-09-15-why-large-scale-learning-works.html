---
layout: blog_layout
title: Why large scale learning works
marked_menu_item: Blog
---

članak o deep learningu!!
komentirati kako osnova teorija, nema veze s biološkim zasad iako inspired + feature repsresentation + generalization + usporedba coin ili nesto
+ overfitting pa dropout
More data uvijek fdobro (pood pretpostavkom isti error)
+ deep learning features - vision tako slicno prepoznaje kao covjek jer je stvarno tako optimalno jer 
- što znaci kad precomputamo
- sparse coding - dobro jer malo parametara
+ i inace u MLu se ne zna znacenje - u NN se potrefilo da detektira edges i to kao i mozak - mozdaslucajno, tko zna - ne znaci da je kao mozak
- što unsupervised cini - kao saznajemo nesto o target function
- kako se mijenja learning curve sa hand engineered features?
- slicno kao i u fizici (zakoni koji priblizno dobro vrijede- tako i ovdje)
don't have enought data - don't be lazy, extract features
- features - ionako se racunaju  bilo da ljudi bilo slojevi
- mistrerious? no - just a simple case of xor - može circle bolje - tako može prakticki bilo sto!! - jednostavnim dodavanjem slojeva - ne zna se koje set of functions moze approximate
+ complex target function (vision, speech recognition, a ocito je komplksno jer d anije, vec bi se otkrilo :) )
+ sve je na sverage - tesko jer real world tako puno i nisam spomenuo unsipervised
radi jer moguce komplekse
-without being experts
- razlika - ne treba domain expertiese
 za digits - umjetno, distortati
- ne uci features  ML ionako ne uci features, tko zna kako mozak
- napomenda da je by vc theory


<p>Testing interactive graph</p>

<script type="text/javascript" src="/javascripts/cdfplugin.js"></script>
<script type="text/javascript">
var cdf = new cdfplugin();
cdf.setDefaultContent('<a href="http://www.wolfram.com/cdf-player/"><img  src="prova.png"></a>');
cdf.embed('/mathematica/test.cdf', 435, 325);
</script>